- [ ] **Sohl-Dickstein, J. et al. (2015).** *Deep Unsupervised Learning using Nonequilibrium Thermodynamics.*  
  Laid the early groundwork for diffusion-based generative models by formulating a diffusion process to gradually transform data into noise.

- [ ] **Ho, J., Jain, A., & Abbeel, P. (2020).** *Denoising Diffusion Probabilistic Models.*  
  Presented a practical framework for training diffusion models that rival GANs in sample quality, sparking renewed interest in diffusion-based methods.

- [ ] **Song, Y. & Ermon, S. (2019).** *Generative Modeling by Estimating Gradients of the Data Distribution.*  
  Introduced score matching techniques that form the basis for later score-based diffusion and stochastic differential equation (SDE) methods.

- [ ] **Song, Y. et al. (2021).** *Score-Based Generative Modeling through Stochastic Differential Equations.*  
  Unified score-based generative models with diffusion processes via SDEs, broadening the theoretical understanding and practical scope of diffusion models.

- [ ] **Dhariwal, P. & Nichol, A. (2021).** *Diffusion Models Beat GANs on Image Synthesis.*  
  Demonstrated that diffusion models can outperform GANs in terms of sample fidelity and diversity, reinforcing the viability of this approach for high-quality image synthesis.

- [ ] **Song, J., Meng, C., & Ermon, S. (2021).** *Denoising Diffusion Implicit Models (DDIM).*  
  Proposed a deterministic sampling method that accelerates the inference process while preserving the quality of generated samples.

- [ ] **Nichol, A. & Dhariwal, P. (2021).** *Improved Denoising Diffusion Probabilistic Models.*  
  Offered refinements to the original diffusion framework that improved sample quality and sampling efficiency through architectural and training modifications.

- [ ] **Kingma, D. P. & Dhariwal, P. (2021).** *Variational Diffusion Models.*  
  Combined ideas from variational inference with diffusion processes, providing a novel perspective and improved generative performance.

- [ ] **Rombach, R. et al. (2021).** *High-Resolution Image Synthesis with Latent Diffusion Models.*  
  Pioneered the use of diffusion in a lower-dimensional latent space, dramatically reducing computational cost while maintaining high-fidelity image synthesis.

- [ ] **Nichol, A., Dhariwal, P., et al. (2021).** *GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models.*  
  Extended diffusion models to text-to-image generation, demonstrating impressive capabilities in photorealistic synthesis and image editing through language conditioning.

- [ ] **Ho, J. et al. (2022).** *Video Diffusion Models.*  
  Extended the diffusion framework to generate high-quality videos by incorporating temporal dynamics and consistency into the model design.

- [ ] **Poole, B. et al. (2022).** *DreamFusion: Text-to-3D using 2D Diffusion.*  
  Bridged 2D diffusion models with 3D content synthesis, enabling the generation of three-dimensional structures guided solely by textual descriptions.

- [ ] **Kong, Z. et al. (2020).** *DiffWave: A Versatile Diffusion Model for Audio Synthesis.*  
  Adapted diffusion techniques for high-fidelity audio waveform generation, showcasing the method’s versatility across different data modalities.

- [ ] **Saharia, C. et al. (2022).** *Palette: Image-to-Image Diffusion Models.*  
  Applied diffusion models to conditional image-to-image translation tasks, highlighting their flexibility in generating diverse and contextually coherent outputs.

- [ ] **Lyu, L. et al. (2022).** *RePaint: Inpainting using Denoising Diffusion Probabilistic Models.*  
  Demonstrated the use of diffusion models for image inpainting, effectively generating plausible image content to fill missing regions while preserving context.

- [ ] BlockDiffusion

- [ ] **Ramesh, A. et al. (2021).** *Zero-Shot Text-to-Image Generation (DALL·E).*  
  Introduced a groundbreaking framework that demonstrated how a model can generate coherent images directly from textual descriptions without task-specific training.

- [ ] **Ramesh, A. et al. (2022).** *Hierarchical Text-Conditional Image Generation with Diffusion Models (DALL·E 2).*  
  Advanced the original DALL·E concept by integrating diffusion models into a hierarchical framework, resulting in higher fidelity images and improved text-image alignment.


